{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994598c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Could not find GPU, using the CPU\n",
      "2\n",
      "10\n",
      "(11,)\n",
      "0\n",
      "T=10 Epoch: 1/40 - Loss: 0.7282 b_loss=0.7282 - T: 0.35s/epoch ,tempo_previto=8.37 min0.05 nl5 QC0\n",
      "1\n",
      "T=10 Epoch: 2/40 - Loss: 0.6195 b_loss=0.6195 - T: 0.27s/epoch ,tempo_previto=6.41 min0.05 nl5 QC0\n",
      "2\n",
      "T=10 Epoch: 3/40 - Loss: 0.5022 b_loss=0.5022 - T: 0.26s/epoch ,tempo_previto=6.14 min0.05 nl5 QC0\n",
      "3\n",
      "T=10 Epoch: 4/40 - Loss: 0.4022 b_loss=0.4022 - T: 0.26s/epoch ,tempo_previto=6.13 min0.05 nl5 QC0\n",
      "4\n",
      "T=10 Epoch: 5/40 - Loss: 0.3475 b_loss=0.3475 - T: 0.25s/epoch ,tempo_previto=6.01 min0.05 nl5 QC0\n",
      "5\n",
      "T=10 Epoch: 6/40 - Loss: 0.3081 b_loss=0.3081 - T: 0.25s/epoch ,tempo_previto=6.05 min0.05 nl5 QC0\n",
      "6\n",
      "T=10 Epoch: 7/40 - Loss: 0.2611 b_loss=0.2611 - T: 0.27s/epoch ,tempo_previto=6.34 min0.05 nl5 QC0\n",
      "7\n",
      "T=10 Epoch: 8/40 - Loss: 0.2263 b_loss=0.2263 - T: 0.26s/epoch ,tempo_previto=6.24 min0.05 nl5 QC0\n",
      "8\n",
      "T=10 Epoch: 9/40 - Loss: 0.2035 b_loss=0.2035 - T: 0.25s/epoch ,tempo_previto=6.02 min0.05 nl5 QC0\n",
      "9\n",
      "T=10 Epoch: 10/40 - Loss: 0.1582 b_loss=0.1582 - T: 0.26s/epoch ,tempo_previto=6.23 min0.05 nl5 QC0\n",
      "10\n",
      "T=10 Epoch: 11/40 - Loss: 0.1432 b_loss=0.1432 - T: 0.27s/epoch ,tempo_previto=6.48 min0.05 nl5 QC0\n",
      "11\n",
      "T=10 Epoch: 12/40 - Loss: 0.1285 b_loss=0.1285 - T: 0.27s/epoch ,tempo_previto=6.31 min0.05 nl5 QC0\n",
      "12\n",
      "T=10 Epoch: 13/40 - Loss: 0.1204 b_loss=0.1204 - T: 0.26s/epoch ,tempo_previto=6.14 min0.05 nl5 QC0\n",
      "13\n",
      "T=10 Epoch: 14/40 - Loss: 0.0947 b_loss=0.0947 - T: 0.31s/epoch ,tempo_previto=7.25 min0.05 nl5 QC0\n",
      "14\n",
      "T=10 Epoch: 15/40 - Loss: 0.0925 b_loss=0.0925 - T: 0.61s/epoch ,tempo_previto=14.57 min0.05 nl5 QC0\n",
      "15\n",
      "T=10 Epoch: 16/40 - Loss: 0.0831 b_loss=0.0831 - T: 0.67s/epoch ,tempo_previto=15.95 min0.05 nl5 QC0\n",
      "16\n",
      "T=10 Epoch: 17/40 - Loss: 0.0796 b_loss=0.0796 - T: 0.67s/epoch ,tempo_previto=15.99 min0.05 nl5 QC0\n",
      "17\n",
      "T=10 Epoch: 18/40 - Loss: 0.0708 b_loss=0.0708 - T: 0.63s/epoch ,tempo_previto=14.99 min0.05 nl5 QC0\n",
      "18\n",
      "T=10 Epoch: 19/40 - Loss: 0.0633 b_loss=0.0633 - T: 0.65s/epoch ,tempo_previto=15.47 min0.05 nl5 QC0\n",
      "19\n",
      "T=10 Epoch: 20/40 - Loss: 0.0642 b_loss=0.0633 - T: 0.57s/epoch ,tempo_previto=13.43 min0.05 nl5 QC0\n",
      "20\n",
      "T=10 Epoch: 21/40 - Loss: 0.0568 b_loss=0.0568 - T: 0.30s/epoch ,tempo_previto=6.98 min0.05 nl5 QC0\n",
      "21\n",
      "T=10 Epoch: 22/40 - Loss: 0.0604 b_loss=0.0568 - T: 0.51s/epoch ,tempo_previto=12.16 min0.05 nl5 QC0\n",
      "22\n",
      "T=10 Epoch: 23/40 - Loss: 0.0561 b_loss=0.0561 - T: 0.76s/epoch ,tempo_previto=18.07 min0.05 nl5 QC0\n",
      "23\n",
      "T=10 Epoch: 24/40 - Loss: 0.0519 b_loss=0.0519 - T: 0.75s/epoch ,tempo_previto=17.70 min0.05 nl5 QC0\n",
      "24\n",
      "T=10 Epoch: 25/40 - Loss: 0.0549 b_loss=0.0519 - T: 0.64s/epoch ,tempo_previto=15.01 min0.05 nl5 QC0\n",
      "25\n",
      "T=10 Epoch: 26/40 - Loss: 0.0467 b_loss=0.0467 - T: 0.58s/epoch ,tempo_previto=13.66 min0.05 nl5 QC0\n",
      "26\n",
      "T=10 Epoch: 27/40 - Loss: 0.0509 b_loss=0.0467 - T: 0.47s/epoch ,tempo_previto=11.02 min0.05 nl5 QC0\n",
      "27\n",
      "T=10 Epoch: 28/40 - Loss: 0.0475 b_loss=0.0467 - T: 0.30s/epoch ,tempo_previto=7.16 min0.05 nl5 QC0\n",
      "28\n",
      "T=10 Epoch: 29/40 - Loss: 0.0531 b_loss=0.0467 - T: 0.33s/epoch ,tempo_previto=7.83 min0.05 nl5 QC0\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from Modules.training_functions import *\n",
    "from Modules.pennylane_functions import *\n",
    "\n",
    "# if gpu available, set device to gpu\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"WARNING: Could not find GPU, using the CPU\")\n",
    "T=10\n",
    "all=np.load(f'Data/dataset_ld_{ld_dim}_{9}.npy')\n",
    "all=all[:200]\n",
    "for i in range(9):\n",
    "    x=np.load(f'Data/dataset_ld_{ld_dim}_{i}.npy')\n",
    "    all=np.concatenate((x[:200],all))\n",
    "\n",
    "mnist_images=all\n",
    "np.random.shuffle(mnist_images)\n",
    "mnist_images = torch.tensor(mnist_images).to(device)\n",
    "\n",
    "# make dataloader\n",
    "data_loader = torch.utils.data.DataLoader(mnist_images, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "qc_array=np.array([0,2,3])\n",
    "min_array=np.array([0.05,0.01,0.005])\n",
    "layer_array=np.array([5,10,20,50])\n",
    "print(NUM_QUBITS)\n",
    "print(T)\n",
    "zero = torch.zeros(BATCH_SIZE, 2**NUM_QUBITS-ld_dim).to(device)\n",
    "for layer_indx in range(len(layer_array)):\n",
    "    n_layer=layer_array[layer_indx]\n",
    "    for q_indx in range(len(qc_array)):\n",
    "        qc=qc_array[q_indx]\n",
    "        for min_indx in range(len(min_array)):\n",
    "            min_b=min_array[min_indx]\n",
    "\n",
    "            betas      = np.insert(np.linspace(10e-8,min_b, T), 0, 0)\n",
    "            print(np.shape(betas))\n",
    "            alphas     = 1 - betas\n",
    "            alphas_bar = np.cumprod(alphas)\n",
    "            pi         = math.pi\n",
    "            betas      = torch.tensor(betas).float().to(device)\n",
    "            alphas     = torch.tensor(alphas).float().to(device)\n",
    "            alphas_bar = torch.tensor(alphas_bar).float().to(device)\n",
    "            theta_1    = Variable(torch.rand((n_layer*3*NUM_QUBITS+n_layer*3*(NUM_QUBITS)), device = device), requires_grad=True)\n",
    "            optimizer = torch.optim.Adam([theta_1], lr = LEARNING_RATE)\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = SCHEDULER_PATIENCE, gamma = SCHEDULER_GAMMA, verbose = False)\n",
    "            trained_thetas_1 = []\n",
    "            loss_history = []\n",
    "            best_loss = 1e10\n",
    "\n",
    "            for epoch in range(NUM_EPOCHS):\n",
    "                print(epoch)\n",
    "\n",
    "                t0 = time.time()\n",
    "                num_batch=0\n",
    "                tot_loss=0\n",
    "\n",
    "                for image_batch in data_loader:\n",
    "\n",
    "                    # extract batch of random times and betas\n",
    "                    t = torch.randint(0, T, size = (BATCH_SIZE, ), device=device)\n",
    "                    betas_batch = betas[t].to(device)\n",
    "                    alphas_batch=alphas_bar[t].to(device)\n",
    "\n",
    "                    # assemble input at t add noise (t+1)\n",
    "                    target_batch = assemble_input(image_batch, t, alphas_bar,ld_dim ,device)\n",
    "                    input_batch  = noise_step(target_batch, t+1, betas,ld_dim, device)\n",
    "                    target_batch = target_batch / torch.norm(target_batch, dim = 1).view(-1, 1)\n",
    "                    input_batch  = input_batch / torch.norm(input_batch, dim = 1).view(-1, 1)\n",
    "                    \n",
    "\n",
    "                    # concatenate the two tensors along the second dimension\n",
    "                    input_batch = torch.cat((input_batch, zero), dim=1)\n",
    "                    target_batch = torch.cat((target_batch, zero), dim=1)\n",
    "                    # Feed to circuit, compute the loss and update the weights\n",
    "                    num_batch+=1\n",
    "                    loss = loss_fn_aq(qc,theta_1,n_layer, input_batch, target_batch)\n",
    "                    tot_loss+=loss.item()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                # append parameters and print loss\n",
    "                trained_thetas_1.append(theta_1.cpu().clone().detach().numpy())\n",
    "\n",
    "                loss_history.append(tot_loss/num_batch)\n",
    "                if loss.item()< best_loss:\n",
    "                    best_loss=loss.item()\n",
    "\n",
    "                # implement learning rate scheduler\n",
    "                scheduler.step()\n",
    "\n",
    "\n",
    "            # print every epoch\n",
    "                print(f'T={T} Epoch: {epoch+1}/{NUM_EPOCHS} - Loss: {loss.item():.4f} b_loss={best_loss:.4f} - T: {time.time()-t0:.2f}s/epoch ,tempo_previto={((time.time()-t0)*(NUM_EPOCHS-1-epoch+NUM_EPOCHS*(len(qc_array)-q_indx-1)+NUM_EPOCHS*len(qc_array)*(len(min_array)-min_indx-1)+NUM_EPOCHS*len(qc_array)*len(min_array)*(len(layer_array)-layer_indx-1)))/60:.2f} min{min_b} nl{n_layer} QC{qc}')\n",
    "                #print(f'T={T} Epoch: {epoch+1}/{NUM_EPOCHS} - Loss: {loss.item():.4f} b_loss={best_loss:.4f} - T: {time.time()-t0:.2f}s/epoch ,tempo_previto={(((NUM_EPOCHS-1-epoch+NUM_EPOCHS*(len(qc_array)-q_indx-1)+NUM_EPOCHS*len(qc_array)*(len(min_array)-min_indx-1)+NUM_EPOCHS*len(qc_array)*len(min_array)*(len(layer_array)-layer_indx-1)))):.2f} min{min_b} nl{n_layer}')\n",
    "                \n",
    "            np.save(f'all_thetas_T{T}_nl{n_layer}_min{min_b}_qc{qc}_{Q_ANCILLA}_ld{ld_dim}_alternativo.npy',trained_thetas_1)\n",
    "            np.save(f'all_loss__T{T}_nl{n_layer}_min{min_b}_qc{qc}_ancilla{Q_ANCILLA}_ld{ld_dim}_alternativo.npy',loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c015f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf45ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c46998c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
