{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994598c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Could not find GPU, using the CPU\n",
      "7\n",
      "5\n",
      "(6,)\n",
      "0\n",
      "T=5 Epoch: 1/25 - Loss: 0.3978 b_loss=0.3978 - T: 1.66s/epoch ,tempo_previto=49.88 min0.05 nl5 QC0\n",
      "1\n",
      "T=5 Epoch: 2/25 - Loss: 0.2376 b_loss=0.2376 - T: 1.69s/epoch ,tempo_previto=50.54 min0.05 nl5 QC0\n",
      "2\n",
      "T=5 Epoch: 3/25 - Loss: 0.1136 b_loss=0.1136 - T: 1.71s/epoch ,tempo_previto=51.29 min0.05 nl5 QC0\n",
      "3\n",
      "T=5 Epoch: 4/25 - Loss: 0.0478 b_loss=0.0478 - T: 1.71s/epoch ,tempo_previto=51.26 min0.05 nl5 QC0\n",
      "4\n",
      "T=5 Epoch: 5/25 - Loss: 0.0259 b_loss=0.0259 - T: 1.69s/epoch ,tempo_previto=50.66 min0.05 nl5 QC0\n",
      "5\n",
      "T=5 Epoch: 6/25 - Loss: 0.0148 b_loss=0.0148 - T: 1.72s/epoch ,tempo_previto=51.56 min0.05 nl5 QC0\n",
      "6\n",
      "T=5 Epoch: 7/25 - Loss: 0.0112 b_loss=0.0112 - T: 1.84s/epoch ,tempo_previto=54.84 min0.05 nl5 QC0\n",
      "7\n",
      "T=5 Epoch: 8/25 - Loss: 0.0085 b_loss=0.0085 - T: 1.68s/epoch ,tempo_previto=50.31 min0.05 nl5 QC0\n",
      "8\n",
      "T=5 Epoch: 9/25 - Loss: 0.0070 b_loss=0.0070 - T: 1.75s/epoch ,tempo_previto=52.28 min0.05 nl5 QC0\n",
      "9\n",
      "T=5 Epoch: 10/25 - Loss: 0.0073 b_loss=0.0070 - T: 1.73s/epoch ,tempo_previto=51.56 min0.05 nl5 QC0\n",
      "10\n",
      "T=5 Epoch: 11/25 - Loss: 0.0070 b_loss=0.0070 - T: 1.75s/epoch ,tempo_previto=52.10 min0.05 nl5 QC0\n",
      "11\n",
      "T=5 Epoch: 12/25 - Loss: 0.0048 b_loss=0.0048 - T: 1.77s/epoch ,tempo_previto=52.69 min0.05 nl5 QC0\n",
      "12\n",
      "T=5 Epoch: 13/25 - Loss: 0.0068 b_loss=0.0048 - T: 1.74s/epoch ,tempo_previto=51.89 min0.05 nl5 QC0\n",
      "13\n",
      "T=5 Epoch: 14/25 - Loss: 0.0051 b_loss=0.0048 - T: 1.78s/epoch ,tempo_previto=52.93 min0.05 nl5 QC0\n",
      "14\n",
      "T=5 Epoch: 15/25 - Loss: 0.0055 b_loss=0.0048 - T: 1.78s/epoch ,tempo_previto=53.08 min0.05 nl5 QC0\n",
      "15\n",
      "T=5 Epoch: 16/25 - Loss: 0.0064 b_loss=0.0048 - T: 1.85s/epoch ,tempo_previto=54.95 min0.05 nl5 QC0\n",
      "16\n",
      "T=5 Epoch: 17/25 - Loss: 0.0054 b_loss=0.0048 - T: 1.94s/epoch ,tempo_previto=57.70 min0.05 nl5 QC0\n",
      "17\n",
      "T=5 Epoch: 18/25 - Loss: 0.0058 b_loss=0.0048 - T: 1.98s/epoch ,tempo_previto=58.86 min0.05 nl5 QC0\n",
      "18\n",
      "T=5 Epoch: 19/25 - Loss: 0.0062 b_loss=0.0048 - T: 2.04s/epoch ,tempo_previto=60.48 min0.05 nl5 QC0\n",
      "19\n",
      "T=5 Epoch: 20/25 - Loss: 0.0061 b_loss=0.0048 - T: 2.09s/epoch ,tempo_previto=61.93 min0.05 nl5 QC0\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from Modules.training_functions import *\n",
    "from Modules.pennylane_functions import *\n",
    "\n",
    "# if gpu available, set device to gpu\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"WARNING: Could not find GPU, using the CPU\")\n",
    "T=5\n",
    "all=np.load(f'Data/dataset_ld_{ld_dim}_{9}.npy')\n",
    "all=all[:200]\n",
    "for i in range(9):\n",
    "    x=np.load(f'Data/dataset_ld_{ld_dim}_{i}.npy')\n",
    "    all=np.concatenate((x[:200],all))\n",
    "\n",
    "mnist_images=all\n",
    "np.random.shuffle(mnist_images)\n",
    "mnist_images = torch.tensor(mnist_images).to(device)\n",
    "\n",
    "# make dataloader\n",
    "data_loader = torch.utils.data.DataLoader(mnist_images, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "qc_array=np.array([0,64,96,112,120,124])\n",
    "min_array=np.array([0.05,0.01,0.005])\n",
    "layer_array=np.array([5,10,20,50])\n",
    "print(NUM_QUBITS)\n",
    "print(T)\n",
    "zero = torch.zeros(BATCH_SIZE, 2**NUM_QUBITS-ld_dim).to(device)\n",
    "for layer_indx in range(len(layer_array)):\n",
    "    n_layer=layer_array[layer_indx]\n",
    "    for q_indx in range(len(qc_array)):\n",
    "        qc=qc_array[q_indx]\n",
    "        for min_indx in range(len(min_array)):\n",
    "            min_b=min_array[min_indx]\n",
    "\n",
    "            betas      = np.insert(np.linspace(10e-8,min_b, T), 0, 0)\n",
    "            print(np.shape(betas))\n",
    "            alphas     = 1 - betas\n",
    "            alphas_bar = np.cumprod(alphas)\n",
    "            pi         = math.pi\n",
    "            betas      = torch.tensor(betas).float().to(device)\n",
    "            alphas     = torch.tensor(alphas).float().to(device)\n",
    "            alphas_bar = torch.tensor(alphas_bar).float().to(device)\n",
    "            theta_1    = Variable(torch.rand((n_layer*3*NUM_QUBITS+n_layer*3*(NUM_QUBITS)), device = device), requires_grad=True)\n",
    "            optimizer = torch.optim.Adam([theta_1], lr = LEARNING_RATE)\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = SCHEDULER_PATIENCE, gamma = SCHEDULER_GAMMA, verbose = False)\n",
    "            trained_thetas_1 = []\n",
    "            loss_history = []\n",
    "            best_loss = 1e10\n",
    "\n",
    "            for epoch in range(NUM_EPOCHS):\n",
    "                print(epoch)\n",
    "\n",
    "                t0 = time.time()\n",
    "                num_batch=0\n",
    "                tot_loss=0\n",
    "\n",
    "                for image_batch in data_loader:\n",
    "\n",
    "                    # extract batch of random times and betas\n",
    "                    t = torch.randint(0, T, size = (BATCH_SIZE, ), device=device)\n",
    "                    betas_batch = betas[t].to(device)\n",
    "                    alphas_batch=alphas_bar[t].to(device)\n",
    "\n",
    "                    # assemble input at t add noise (t+1)\n",
    "                    target_batch = assemble_input(image_batch, t, alphas_bar,ld_dim ,device)\n",
    "                    input_batch  = noise_step(target_batch, t+1, betas,ld_dim, device)\n",
    "                    target_batch = target_batch / torch.norm(target_batch, dim = 1).view(-1, 1)\n",
    "                    input_batch  = input_batch / torch.norm(input_batch, dim = 1).view(-1, 1)\n",
    "                    \n",
    "\n",
    "                    # concatenate the two tensors along the second dimension\n",
    "                    input_batch = torch.cat((input_batch, zero), dim=1)\n",
    "                    target_batch = torch.cat((target_batch, zero), dim=1)\n",
    "                    # Feed to circuit, compute the loss and update the weights\n",
    "                    num_batch+=1\n",
    "                    loss = loss_fn_aq(qc,theta_1,n_layer, input_batch, target_batch)\n",
    "                    tot_loss+=loss.item()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                # append parameters and print loss\n",
    "                trained_thetas_1.append(theta_1.cpu().clone().detach().numpy())\n",
    "\n",
    "                loss_history.append(tot_loss/num_batch)\n",
    "                if loss.item()< best_loss:\n",
    "                    best_loss=loss.item()\n",
    "\n",
    "                # implement learning rate scheduler\n",
    "                scheduler.step()\n",
    "\n",
    "\n",
    "            # print every epoch\n",
    "                print(f'T={T} Epoch: {epoch+1}/{NUM_EPOCHS} - Loss: {loss.item():.4f} b_loss={best_loss:.4f} - T: {time.time()-t0:.2f}s/epoch ,tempo_previto={((time.time()-t0)*(NUM_EPOCHS-1-epoch+NUM_EPOCHS*(len(qc_array)-q_indx-1)+NUM_EPOCHS*len(qc_array)*(len(min_array)-min_indx-1)+NUM_EPOCHS*len(qc_array)*len(min_array)*(len(layer_array)-layer_indx-1)))/60:.2f} min{min_b} nl{n_layer} QC{qc}')\n",
    "                #print(f'T={T} Epoch: {epoch+1}/{NUM_EPOCHS} - Loss: {loss.item():.4f} b_loss={best_loss:.4f} - T: {time.time()-t0:.2f}s/epoch ,tempo_previto={(((NUM_EPOCHS-1-epoch+NUM_EPOCHS*(len(qc_array)-q_indx-1)+NUM_EPOCHS*len(qc_array)*(len(min_array)-min_indx-1)+NUM_EPOCHS*len(qc_array)*len(min_array)*(len(layer_array)-layer_indx-1)))):.2f} min{min_b} nl{n_layer}')\n",
    "                \n",
    "            np.save(f'thetas_T{T}_nl{n_layer}_min{min_b}_qc{qc}_{Q_ANCILLA}_ld{ld_dim}.npy',trained_thetas_1)\n",
    "            np.save(f'loss__T{T}_nl{n_layer}_min{min_b}_qc{qc}_ancilla{Q_ANCILLA}_ld{ld_dim}.npy',loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c015f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf45ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c46998c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
